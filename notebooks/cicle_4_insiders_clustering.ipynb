{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# <font color = '#00CCFF'> High Value Customer Identification </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Objective: Find significant customers for the business who make high purchases of their favourite products. The organization wants to roll out a loyalty program to the high-value customers after identification of segments. Use the clustering methodology to segment customers into groups:\n",
    "\n",
    "Dataset Description: This is a transnational dataset that contains all the transactions occurring between Nov-2016 to Dec-2017 for a UK-based online retail store.\n",
    "\n",
    "Attribute Description:\n",
    "- InvoiceNo: Invoice number (A 6-digit integral number uniquely assigned to each transaction)\n",
    "- StockCode: Product (item) code\n",
    "- Description: Product (item) name\n",
    "- Quantity: The quantities of each product (item) per transaction\n",
    "- InvoiceDate: The day when each transaction was generated\n",
    "- UnitPrice: Unit price (Product price per unit)\n",
    "- CustomerID: Customer number (Unique ID assigned to each customer)\n",
    "- Country: Country name (The name of the country where each customer resides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "import plotly.express as px\n",
    "#%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import umap.umap_ as umap\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save intermediate dataset\n",
    "def save_interim(dataframe, file_name):\n",
    "   dataframe.to_csv('../data/interim/'+file_name+'.zip', index=False, compression= 'zip')\n",
    "\n",
    "# Load intermediate dataset\n",
    "def load_interim(file_name):\n",
    "   return pd.read_csv('../data/interim/'+file_name, compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ezequiel/Documentos/Comunidade_DS/insiders_clustering/data/raw/Ecommerce.zip'\n",
    "df_raw = pd.read_csv(path, encoding='unicode_escape', compression='zip')\n",
    "df_raw = df_raw.drop(columns=['Unnamed: 8'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Descrição dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['invoice_no', 'stock_code', 'description', 'quantity', 'invoice_date', 'unit_price', 'customer_id', 'country']\n",
    "df1.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of rows: {df1.shape[0]}')\n",
    "print(f'Number of columns: {df1.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InvoiceNo should be a number, but some records have letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Replace NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procurar se há algum customer_id \"perdido\" a partir do invoice_no\n",
    "df_missing = df1[df1['customer_id'].isna()]\n",
    "df_not_missing = df1[~df1['customer_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_invoice = df_missing['invoice_no'].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Os invoice_no dos customer_id faltantes não correspondem a nenhum invoice_no que possui um customer_id\n",
    "df_not_missing.loc[df_not_missing['invoice_no'].isin(missing_invoice), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_missing['customer_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternativa: atribuir um customer_id não utilizado para cada invoice_no único que não possui customer_id\n",
    "aux = df_missing[['invoice_no']].drop_duplicates()\n",
    "aux['customer_id'] = np.arange(19000, 19000+len(aux), 1)\n",
    "\n",
    "df1 = pd.merge(df1, aux, on='invoice_no', how='left')\n",
    "df1['customer_id'] = df1['customer_id_x'].combine_first(df1['customer_id_y'])\n",
    "df1.drop(columns=['customer_id_x', 'customer_id_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.dropna(subset=['description', 'customer_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Change dtyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoice_date -> to datetime\n",
    "df1['invoice_date'] = pd.to_datetime(df1['invoice_date'], format='%d-%b-%y')\n",
    "\n",
    "# customer_id -> to int\n",
    "df1['customer_id'] = df1['customer_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_interim(dataframe=df1, file_name='df1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attributes = df1.select_dtypes(include=['int64', 'float64'])\n",
    "cat_attributes = df1.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7.1. Numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_describe = num_attributes.describe().T\n",
    "df_describe['range'] = df_describe['max'] - df_describe['min']\n",
    "df_describe['median'] = num_attributes.median()\n",
    "df_describe['skewness'] = num_attributes.skew()\n",
    "df_describe['kurtosis'] = num_attributes.kurtosis()\n",
    "df_describe.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**OBSERVAÇÕES:**</font>\n",
    "- quantity com mínimo negativo (devolução?)\n",
    "- quantity com valor max e min iguais em módulo\n",
    "- unit_price com min = zero (promoção?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7.2. Categorical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoice_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifica se invoice_no contém, ao menos, uma letra e agrupa por invoice_no para o dataframe inteiro\n",
    "aux = df1[df1['invoice_no'].str.contains('[a-zA-Z]')].groupby('invoice_no').count().reset_index()\n",
    "print(f'Qtd de invoices únicos com letras: {len(aux)}')\n",
    "print(f'Qtd total de invoices com letras {aux[\"stock_code\"].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = len(df1.loc[df1['invoice_no'].str.contains('[a-zA-Z]'), ['quantity']])\n",
    "print(f'Qtd de invoices com letras onde a quantidade é negativa: {aux}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifica se stock_code contém, ao menos, uma letra e conta quantos são\n",
    "df1[df1['stock_code'].str.contains('[a-zA-Z]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifica se stock_code contém somente letras e mostra a quantidade de ocorrências\n",
    "df1.loc[~df1['stock_code'].str.contains('[0-9]'), 'stock_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[~df1['stock_code'].str.contains('[0-9]'), 'stock_code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['country'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**OBSERVAÇÕES:**</font>\n",
    "- invoice_no possui:\n",
    "    - 3839 entradas únicas que possuem letras\n",
    "    - 9291 entradas totais que possuem letras\n",
    "    - todas as entradas com letras correspondem à uma quantity negativa, indicando uma operação de cancelamento de venda\n",
    "- stock_code que possuem somente letras:\n",
    "    - BANK CHARGES -> qtd: 37\n",
    "    - AMAZONFEE ->    qtd: 34\n",
    "    - CRUK ->         qtd: -16\n",
    "    - D ->            qtd: 77\n",
    "    - DOT ->          qtd: 710\n",
    "    - M ->            qtd: 571\n",
    "    - S ->            qtd: 63\n",
    "    - POST ->         qtd: 1256\n",
    "    - DCGSSGIRL ->    qtd: 13\n",
    "    - DCGSSBOY ->     qtd: 11\n",
    "    - PADS ->         qtd: 4\n",
    "    - B ->            qtd: 3\n",
    "    - m ->            qtd: 1\n",
    "- description:\n",
    "    - deletar coluna pois, a princípio, não tem relevância como feature\n",
    "- country:\n",
    "    - 91,43% está no Reino Unido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile = ProfileReport(df=df1, title='Profiling report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Variables Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.query('quantity < 0').sort_values('quantity').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.query('customer_id == 20914')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecionar somente preços maiores que 4 centavo\n",
    "df2 = df2.query('unit_price >= 0.04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retirar alguns stock_codes\n",
    "codes = ['POST', 'D', 'DOT', 'M', 'BANK CHARGES', 'S', 'AMAZONFEE', 'm', 'DCGSSBOY', 'DCGSSGIRL', 'PADS', 'B', 'CRUK']\n",
    "df2 = df2.query('stock_code != @codes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(columns='description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_country = ['European Community', 'Unspecified']\n",
    "df2 = df2.query('country != @drop_country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separar as quantidades negativas como devoluções (cancelamentos)\n",
    "df2_returns = df2.query('quantity < 0')\n",
    "df2_purchases = df2.query('quantity >= 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_interim(dataframe=df2, file_name='df2.csv')\n",
    "save_interim(dataframe=df2_returns, file_name='df2_returns.csv')\n",
    "save_interim(dataframe=df2_purchases, file_name='df2_purchases.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data reference - group by customer\n",
    "df_ref = df3[['customer_id']].drop_duplicates(ignore_index=True)\n",
    "df_ref.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Gross revenue (Faturamento)**\n",
    "\n",
    "Faturamento para cada produto = quantidade x preço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_purchases['gross_revenue'] = df2_purchases['quantity'] * df2_purchases['unit_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total value of purchases per customer\n",
    "df_monetary = df2_purchases[['customer_id', 'gross_revenue']].groupby('customer_id').sum().reset_index()\n",
    "df_ref = pd.merge(df_ref, df_monetary, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Recency**\n",
    "\n",
    "How recent is the last purchase made by each customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the last purchase date of each customer and subtracts of the overall last purchase date\n",
    "df_last_purchase = df2_purchases[['customer_id', 'invoice_date']].groupby('customer_id').max().reset_index()\n",
    "df_last_purchase['recency'] = (df_last_purchase['invoice_date'].max() - df_last_purchase['invoice_date']).dt.days\n",
    "df_ref = pd.merge(df_ref, df_last_purchase, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Quantity of purchases**\n",
    "\n",
    "Consider the unique invoice_no (transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = df2_purchases[['customer_id', 'invoice_no']].drop_duplicates().groupby('customer_id').count().reset_index()\n",
    "df_ref = pd.merge(df_ref, df_freq, on='customer_id', how='left')\n",
    "df_ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Quantity of products purchased**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = df2_purchases.loc[:, ['customer_id', 'quantity']].drop_duplicates().groupby('customer_id').count().reset_index()\n",
    "df_ref = pd.merge(df_ref, aux, on='customer_id', how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Average ticket**\n",
    "\n",
    "Average spend of each client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_ticket = df2_purchases[['customer_id', 'gross_revenue']].groupby('customer_id').mean().reset_index().rename(columns={'gross_revenue': 'avg_ticket'})\n",
    "df_ref = pd.merge(df_ref, df_avg_ticket, how='left', on='customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Average recency days**\n",
    "\n",
    "Average days between purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = df3[['customer_id', 'invoice_date']].drop_duplicates().sort_values(['customer_id', 'invoice_date'], ascending=[False, False])\n",
    "df_aux['next_customer_id'] = df_aux['customer_id'].shift()\n",
    "df_aux['previous_date'] = df_aux['invoice_date'].shift()\n",
    "\n",
    "df_aux['avg_recency_days'] = df_aux.apply(lambda x: (x['invoice_date'] - x['previous_date']).days if x['customer_id'] == x['next_customer_id'] else np.nan, axis=1)\n",
    "\n",
    "df_aux = df_aux.drop(['invoice_date', 'next_customer_id', 'previous_date'], axis=1).dropna()\n",
    "\n",
    "df_avg_recency_days = df_aux.groupby('customer_id').mean().reset_index()\n",
    "\n",
    "df_ref = pd.merge(df_ref, df_avg_recency_days, on='customer_id', how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Frequency purchase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = df3[['customer_id', 'invoice_no', 'invoice_date']].drop_duplicates().groupby('customer_id').agg(\n",
    "                                                            max_inv_date = ('invoice_date', max),\n",
    "                                                            min_inv_date = ('invoice_date', min),\n",
    "                                                            days = ('invoice_date', lambda x: (x.max() - x.min()).days + 1),\n",
    "                                                            buy = ('invoice_no', 'count')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency\n",
    "df_aux['frequency'] = df_aux[['buy', 'days']].apply(lambda x: x['buy']/x['days'] if x['days'] != 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref = pd.merge(df_ref, df_aux[['customer_id', 'frequency']], on='customer_id', how='left')\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Number of returns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns = df2_returns[['customer_id', 'quantity']].groupby('customer_id').sum().reset_index().rename(columns={'quantity': 'returns'})\n",
    "df_returns['returns'] = df_returns['returns'] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref= pd.merge(df_ref, df_returns, on='customer_id', how='left')\n",
    "df_ref.loc[df_ref['returns'].isna(), 'returns'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Basket size** (quantidade de itens por cesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = df2_purchases.loc[:, ['customer_id', 'invoice_no', 'quantity']].groupby('customer_id').agg(\n",
    "                                                                        n_purchase = ('invoice_no', 'nunique'),\n",
    "                                                                        n_products = ('quantity', 'sum')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux['avg_basket_size'] = df_aux['n_products'] / df_aux['n_purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref = pd.merge(df_ref, df_aux[['customer_id', 'avg_basket_size']], on='customer_id', how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.hist(bins=50, figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.hist(bins=75, figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df_ref.dropna().copy()\n",
    "df4.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler =StandardScaler()\n",
    "\n",
    "df5['gross_revenue'] = std_scaler.fit_transform(df5[['gross_revenue']])\n",
    "df5['recency'] = std_scaler.fit_transform(df5[['recency']])\n",
    "df5['invoice_no'] = std_scaler.fit_transform(df5[['invoice_no']])\n",
    "df5['avg_ticket'] = std_scaler.fit_transform(df5[['avg_ticket']])\n",
    "#df5['returns'] = std_scaler.fit_transform(df5[['returns']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Hyperparameter Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df5.drop(columns=['returns'])\n",
    "df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Within-Cluster Sum of Squares (WSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the compactness of the clusters. It is global measure and does not tell if the clusters are well separated or if there is overlaping between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [2, 3, 4, 5, 6, 7]\n",
    "model = KMeans(n_init=10)\n",
    "elbow = KElbowVisualizer(estimator=model, k=clusters)\n",
    "elbow.fit(df7)\n",
    "elbow.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = KElbowVisualizer(estimator=model, k=clusters, metric='silhouette', timings=False)\n",
    "S.fit(df7)\n",
    "S.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Silhouette Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measures how well a point fits into its cluster compared to the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,2, figsize=(16,20))\n",
    "\n",
    "for k in clusters:\n",
    "    km_model = KMeans(n_clusters=k, init='random', n_init=10, max_iter=100, random_state=42)\n",
    "    x, y = divmod(k, 2)\n",
    "    SS = SilhouetteVisualizer(estimator=km_model, colors='yellowbrick', ax=ax[x-1][y])\n",
    "    SS.fit(df7)\n",
    "    SS.finalize()\n",
    "    #SS.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "\n",
    "kmeans = KMeans(n_clusters=k, init='random', n_init=10, max_iter=300, random_state=42)\n",
    "kmeans.fit(df7)\n",
    "labels = kmeans.predict(df7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.1. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WSS\n",
    "print(f'WSS: {kmeans.inertia_}')\n",
    "\n",
    "# SS\n",
    "print(f'Silhouette score: {silhouette_score(X=df7, labels=labels, metric=\"euclidean\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Cluster Analisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df7.copy()\n",
    "df9['cluster'] = labels\n",
    "df9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_fig = SilhouetteVisualizer(kmeans, colors='sns_dark')\n",
    "SS_fig.fit(df7)\n",
    "SS_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = px.scatter_3d(data_frame=df9, x='gross_revenue', y='recency', z='invoice_no', color='cluster', width=600, height=600)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.1. 2d plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz = df9.drop(columns='customer_id')\n",
    "sns.pairplot(data=df_viz, hue='cluster', corner=True, palette='Set1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.2. UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ferramenta para visualização de dados com alta dimensionalidade em um plano 2D.\n",
    "- Clusters com boa definição (bom agrupamento) em 2D indicam um bom agrupamento na alta dimensionalidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_neighbors=90, n_jobs=-1)\n",
    "embedding = reducer.fit_transform(df9)\n",
    "\n",
    "df_viz['embedding_x'] = embedding[:, 0]\n",
    "df_viz['embedding_y'] = embedding[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='embedding_x',\n",
    "                y='embedding_y',\n",
    "                hue='cluster',\n",
    "                palette=sns.color_palette('hls', n_colors=len(df_viz['cluster'].unique())),\n",
    "                data=df_viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. Cluster profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9['gross_revenue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9[['cluster', 'gross_revenue']].groupby('cluster').sum() / df9['gross_revenue'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of customers\n",
    "df_clusters = df9[['customer_id', 'cluster']].groupby('cluster').count().reset_index()\n",
    "\n",
    "# Number of customers (%)\n",
    "df_clusters['% customer_id'] = (df_clusters[['customer_id']] / df_clusters[['customer_id']].sum()) * 100\n",
    "\n",
    "# Average gross revenue\n",
    "aux1 = df9[['gross_revenue', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "\n",
    "# % Gross revenue\n",
    "aux2 = (df9[['cluster', 'gross_revenue']].groupby('cluster').sum() / df9['gross_revenue'].sum()).reset_index().rename(columns={'gross_revenue': '% gross_revenue'})\n",
    "\n",
    "# Average recency\n",
    "aux3 = df9[['recency', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "\n",
    "# Average invoice no\n",
    "aux4 = df9[['invoice_no', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "\n",
    "# Average ticket\n",
    "aux5 = df9[['avg_ticket', 'cluster']].groupby('cluster').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = pd.merge(df_clusters, aux1, on='cluster', how='left')\n",
    "df_clusters = pd.merge(df_clusters, aux2, on='cluster', how='left')\n",
    "df_clusters = pd.merge(df_clusters, aux3, on='cluster', how='left')\n",
    "df_clusters = pd.merge(df_clusters, aux4, on='cluster', how='left')\n",
    "df_clusters = pd.merge(df_clusters, aux5, on='cluster', how='left')\n",
    "df_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Cluster 1 (candidatos à insiders)**:\n",
    "- Número de customers: 267 (6,1%)\n",
    "- Recência média: 20,28\n",
    "- Média de compras: 19,5\n",
    "- Média de receita: US$ 8.089,00\n",
    "- Ticket médio: US$ 62,78\n",
    "---\n",
    "\n",
    "**Cluster 2**:\n",
    "- Número de customers: 6 (0,14%)\n",
    "- Recência média: 7,16\n",
    "- Média de compras: 89\n",
    "- Média de receita: US$ 182.181,98\n",
    "- Ticket médio: US$ 253,62\n",
    "---\n",
    "\n",
    "**Cluster 3**:\n",
    "- Número de customers: 28 (0,64%)\n",
    "- Recência média: 6,18\n",
    "- Média de compras: 57,82\n",
    "- Média de receita: US$ 42.614,39\n",
    "- Ticket médio: US$ 162,86\n",
    "---\n",
    "\n",
    "**Cluster 4**:\n",
    "- Número de customers: 4071 (93,1%)\n",
    "- Recência média: 96,96\n",
    "- Média de compras: 3,64\n",
    "- Média de receita: US$ 946,69\n",
    "- Ticket médio: US$ 25,35\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Deploy to Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
